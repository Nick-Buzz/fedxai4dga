{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1nP7xRXwTLnj79EDMrBnDg71MBWub6Ied","authorship_tag":"ABX9TyMes73lhBgioF7UJ+zPSqZg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KGCqte2EIaIs","executionInfo":{"status":"ok","timestamp":1717662284053,"user_tz":-180,"elapsed":10286,"user":{"displayName":"Νίκος Μπαζώτης","userId":"12173468501181175845"}}},"outputs":[],"source":["import numpy as np\n","import scipy.stats as stats\n","import pandas as pd\n","from sklearn.decomposition import PCA\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from scipy import stats\n","from datetime import datetime\n","import os\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix, classification_report\n","#from ops import helper\n","plt.rcParams.update({'figure.max_open_warning': 0})\n","from tensorboard import program\n","from tensorflow.python.keras.callbacks import TensorBoard\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Model, load_model\n","from keras.layers import Input,Lambda, Dense, Dropout, LeakyReLU, BatchNormalization\n","from keras.losses import mse, binary_crossentropy, kl_divergence\n","from keras import optimizers\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"markdown","metadata":{"id":"lr2EzdqYAjiX"},"source":["## Functions"]},{"cell_type":"markdown","metadata":{"id":"pxH0eeh1WBXO"},"source":["### create_experiment_folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7w_nITQ2V5yE"},"outputs":[],"source":["from keras.api._v2.keras.callbacks import experimental\n","def create_experiment_folder(model, experiment):\n","    mode = \"/content/drive/MyDrive/Intrusion Detection System_Thesis/Experiments/{models}/\"\n","    date_now = experiment +\"/\"\n","    folder_path = os.path.join(mode.format(models=model), date_now )\n","\n","    if not os.path.isdir(folder_path):\n","        os.makedirs(folder_path)\n","\n","    output_file = \"Configuration.csv\"\n","    output_file = os.path.join(folder_path, output_file)\n","\n","    return folder_path, output_file"]},{"cell_type":"markdown","metadata":{"id":"-dAjzQ4AV93L"},"source":["### callback_configurationn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8EaBG59sV81_"},"outputs":[],"source":["def callback_configurationn(folder_path,model,csv_log=False,tensorboard=False):\n","    log_dir = f\"{folder_path}logs/fit/\"               # logs\n","    callbacks=[]\n","    if csv_log:\n","      csv_logger = tf.keras.callbacks.CSVLogger(f\"{log_dir}/csv_logger.csv\", separator=',', append=False)\n","      callbacks.append(csv_logger)\n","\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","    callbacks.append(early_stopping)\n","    if tensorboard:\n","      tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","      callbacks.append(tensorboard_callback)\n","      tracking_address = f\"/content/drive/MyDrive/Intrusion Detection System_Thesis/Experiments/{model}/\"\n","      tb = program.TensorBoard()\n","      tb.configure(argv=[None, '--logdir', tracking_address])\n","      url = tb.launch()\n","      print(f\"Tensorflow listening on {url}\")\n","\n","    return callbacks"]},{"cell_type":"markdown","metadata":{"id":"IBYxeCZEAhAb"},"source":["### add_noise"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMJx6zz5Ae_M"},"outputs":[],"source":["def add_noise(dataset, mu=0, sigma=0.1):\n","    dim = list(dataset.shape)\n","    # creating a noise with the same dimension as the dataset\n","    noise = np.random.normal(mu, sigma, dim)\n","    signal = dataset + noise\n","    return signal, noise"]},{"cell_type":"markdown","metadata":{"id":"d6LN4pKKAZtD"},"source":["###plot_confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZGC6wj7b_83G"},"outputs":[],"source":["def plot_confusion_matrix(cm):\n","    fig, ax = plt.subplots(figsize=(8, 8))\n","    cax = ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            count = cm[i, j]\n","            pct = f\"{100*count/np.sum(cm):.2f}%\"\n","            ax.text(x=j, y=i, s=f\"{count}\\n{pct}\", va='center', ha='center', size='xx-large')\n","    fig.colorbar(cax)\n","    plt.xlabel('Predictions', fontsize=18)\n","    plt.ylabel('Ground Truth', fontsize=18)\n","    ax.set_xticklabels([''] + [\"normal\", \"attacks\"])\n","    ax.set_yticklabels([''] + [\"normal\", \"attacks\"])\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","    return fig\n"]},{"cell_type":"markdown","metadata":{"id":"t1WcB-5FAW5P"},"source":["### plot_latent_space"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d6Y0-l1_frg"},"outputs":[],"source":["def plot_latent_space(test_samples, train_samples, attack_labels_df, folder_path=None):\n","    # Extract the attack labels from the dataframe\n","    attack_labels = attack_labels_df['label'].values\n","\n","    # Perform PCA on the encoded samples\n","    pca = PCA(n_components=2)\n","    hidden_2d = pca.fit_transform(test_samples)\n","    hidden_2d_train = pca.fit_transform(train_samples)\n","\n","    # Create a figure with two subplots\n","    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n","\n","    # Plot the training data in the first subplot\n","    sns.scatterplot(x=hidden_2d_train[:, 0], y=hidden_2d_train[:, 1], hue=['normal']*len(hidden_2d_train),alpha=0.6,\n","                    ax=axs[0])\n","    axs[0].set_title(\"Training Data - Latent Space\")\n","\n","    # Plot the test data in the second subplot\n","    # Plot the test data in the second subplot with legend labels\n","    sns.scatterplot(x=hidden_2d[:, 0], y=hidden_2d[:, 1], hue=attack_labels, alpha=0.6,\n","                    hue_norm=(0, 1), palette={0: 'blue', 1: 'red'}, ax=axs[1])\n","    axs[1].set_title(\"Test Data - Latent Space\")\n","    # Set the legend labels\n","    handles, labels = axs[1].get_legend_handles_labels()\n","    labels = ['Normal', 'Attacks']\n","    axs[1].legend(handles, labels)\n","    plt.show()\n","    # Save the figure\n","    if folder_path!=None:\n","      plt.savefig(f\"{folder_path}Latent_space_2D.png\")\n","\n","    return fig"]},{"cell_type":"markdown","metadata":{"id":"1BnogamZAz2n"},"source":["###plot_probability_density"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GOhblMIV-vj-"},"outputs":[],"source":["def plot_probability_density(array, output_file, threshold):\n","    cutoffvalue = np.percentile(array[array[\"attack_label\"] != \"BENIGN\"][\"reconstruction_loss\"], 95)\n","    # Map any reconstruction loss value above the cutoff value to the cutoff value\n","    array.loc[array[\"reconstruction_loss\"] > cutoffvalue, \"reconstruction_loss\"] = cutoffvalue\n","    # Split the array into normal and attack traffic based on the attack label\n","    normal = array[array[\"attack_label\"] == \"BENIGN\"][\"reconstruction_loss\"]\n","    attack = array[array[\"attack_label\"] != \"BENIGN\"][\"reconstruction_loss\"]\n","    # Create a figure and axis object\n","    fig, ax = plt.subplots(figsize=(10, 6))\n","    # Generate the kernel density estimate (KDE) plot for normal traffic using sns.distplot\n","    sns.distplot(normal, hist=True, kde=True, rug=False, fit=stats.norm,\n","                 color='darkblue',\n","                 hist_kws={'edgecolor': 'black'},\n","                 kde_kws={'linewidth': 2, 'label': 'KDE_normal'},\n","                 fit_kws={'color': 'blue', 'alpha': 0.5, 'linewidth': 2, 'label': 'PDF_normal'},\n","                 ax=ax)\n","    # Generate the kernel density estimate (KDE) plot for attack traffic using sns.distplot\n","    sns.distplot(attack, hist=True, kde=True, rug=False, fit=stats.norm,\n","                 color='red',\n","                 hist_kws={'edgecolor': 'black'},\n","                 kde_kws={'linewidth': 2, 'label': 'KDE_attack'},\n","                 fit_kws={'color': 'red', 'alpha': 0.5, 'linewidth': 2, 'label': 'PDF_attack'},\n","                 ax=ax)\n","    # Add a vertical line at the threshold value\n","    ax.axvline(x=threshold, linestyle='--', color='black', label='Threshold')\n","    # Add a tick at the threshold value on the x-axis\n","    ax.set_xticks(list(ax.get_xticks()) + [threshold])\n","    # Set the x-axis label\n","    plt.xlabel(\"mse\")\n","    # Set the y-axis label\n","    plt.ylabel(\"Density\")\n","    # Set the plot title\n","    plt.title(\n","        f\"PDF and KDE of mean square error \\n (cut-off at mse = {round(cutoffvalue, 2)} s.th. mse > {round(cutoffvalue, 2)} is mapped to {round(cutoffvalue, 2)})\")\n","    # Add a legend\n","    plt.legend(loc='best')\n","    # Save the plot to a file\n","    plt.savefig(output_file.replace(\".png\", \"_kde.png\"))\n","    # Show the plot\n","    plt.show()\n","    # Generate a separate plot for the probability density function (PDF) using sns.distplot\n","    fig, ax = plt.subplots(figsize=(10, 6))\n","    # Generate the PDF plot for normal traffic using sns.distplot\n","    sns.distplot(normal, hist=False, kde=False, rug=False, fit=stats.norm,\n","                 color='darkblue',\n","                 hist_kws={'edgecolor': 'black'},\n","                 fit_kws={'color': 'blue', 'linewidth': 2, 'label': 'PDF_normal'}, ax=ax)\n","    # Generate the PDF plot for attack traffic using sns.distplot\n","    sns.distplot(attack, hist=False, kde=False, rug=False, fit=stats.norm,\n","                 color='red',\n","                 hist_kws={'edgecolor': 'black'},\n","                 fit_kws={'color': 'red', 'linewidth': 2, 'label': 'PDF_attack'}, ax=ax)\n","    # Add a vertical line at the threshold value\n","    ax.axvline(x=threshold, linestyle='--', color='black', label='Threshold')\n","    # Add a tick at the threshold value on the x-axis\n","    ax.set_xticks(list(ax.get_xticks()) + [threshold])\n","    # Set the x-axis label\n","    plt.xlabel(\"mse\")\n","    # Set the y-axis label\n","    plt.ylabel(\"Density\")\n","    # Set the plot title\n","    plt.title(\n","        f\"PDF of mean square error \\n (cut-off at mse = {round(cutoffvalue, 2)} s.th. mse > {round(cutoffvalue, 2)} is mapped to {round(cutoffvalue, 2)})\")\n","    # Add a legend\n","    plt.legend(loc='best')\n","    # Save the plot to a file\n","    plt.savefig(output_file.replace(\".png\", \"_pdf.png\"))\n","    # Show the plot\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"w_80vzbrA5Pp"},"source":["### plot_probability_density_att"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PREdBiJx-qii"},"outputs":[],"source":["def plot_probability_density_att(dataset, output_file, threshold):\n","    cutoffvalue = np.percentile(dataset[dataset[\"attack_label\"] != \"BENIGN\"][\"reconstruction_loss\"], 95)\n","    # Map any reconstruction loss value above the cutoff value to the cutoff value\n","    dataset.loc[dataset[\"reconstruction_loss\"] > cutoffvalue, \"reconstruction_loss\"] = cutoffvalue\n","    # Create a figure and axis object\n","    fig, ax = plt.subplots(figsize=(10, 10))\n","    # Get the unique attack labels\n","    attack_labels = dataset[\"attack_label\"].unique()\n","    color_map = plt.get_cmap('tab20')\n","    cmap = [color_map(i) for i in np.linspace(0, 1, 14)]\n","    data_to_plot = []\n","    labels_to_plot = []\n","    for label in attack_labels:\n","        # Get the subset of the dataset for the current attack label\n","        attack_data = dataset.loc[dataset[\"attack_label\"] == label, \"reconstruction_loss\"]\n","        if len(attack_data) > 2 and label != \"BENIGN\":\n","            data_to_plot.append(attack_data.tolist())\n","            labels_to_plot.append(label)\n","    attack_labels = labels_to_plot\n","    # Generate boxplots for the data\n","    bp = ax.boxplot(data_to_plot, labels=attack_labels[:], patch_artist=True)\n","    # Set the colors of the boxplots and the vertical lines\n","    for i, box in enumerate(bp[\"boxes\"]):\n","        box.set_facecolor(cmap[i % len(cmap)])\n","        box.set_edgecolor('black')\n","    for line in bp[\"medians\"]:\n","        line.set_color('black')\n","    for line in bp[\"whiskers\"]:\n","        line.set_color('black')\n","    for line in bp[\"caps\"]:\n","        line.set_color('black')\n","    # Add a horizontal line at the threshold value\n","    ax.axhline(y=threshold, linestyle='--', color='black', label='Threshold')\n","    # Add a tick at the threshold value\n","    ax.yaxis.set_ticks(list(ax.get_yticks()) + [threshold])\n","    # Set the x-axis label\n","    plt.xlabel(\"Attack Label\")\n","    # Set the y-axis label\n","    plt.ylabel(\"mse\")\n","    # Set the plot title\n","    plt.title(\n","        f\"Boxplot of mean square error \\n (cut-off at mse = {round(cutoffvalue, 2)} s.th. mse > {round(cutoffvalue, 2)} is mapped to {round(cutoffvalue, 2)})\")\n","    # Add a legend\n","    plt.legend(loc='best')\n","    # Rotate the x-axis labels by 45 degrees for better visibility\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n","    # Save the plot to a file\n","    plt.savefig(output_file.replace(\".png\", \"_attacks_boxplot.png\"))\n","    # Show the plot\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XQt7Hr4kM7ce"},"source":["### plot_train_reconstruction_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IR-pS97OY5OS"},"outputs":[],"source":["def plot_train_reconstruction_loss(train_reconstruction_loss, threshold):\n","    cutoffvalue = np.percentile(train_reconstruction_loss, 99)\n","    # Map any reconstruction loss value above the cutoff value to the cutoff value\n","    train_reconstruction_loss[train_reconstruction_loss > cutoffvalue] = cutoffvalue\n","    # Create a figure and axis object\n","    fig, ax = plt.subplots(figsize=(10, 6))\n","    # Generate the kernel density estimate (KDE) plot for train reconstruction loss using sns.distplot\n","    sns.distplot(train_reconstruction_loss, hist=True, kde=True, rug=False, fit=stats.norm,\n","                 color='darkblue',\n","                 hist_kws={'edgecolor': 'black'},\n","                 kde_kws={'linewidth': 2, 'label': 'KDE_train_reconstruction_loss'},\n","                 fit_kws={'color': 'blue', 'alpha': 0.5, 'linewidth': 2, 'label': 'PDF_train_reconstruction_loss'},\n","                 ax=ax)\n","    # Add a vertical line at the threshold value\n","    ax.axvline(x=threshold, linestyle='--', color='black', label='Threshold')\n","    # Add a tick at the threshold value on the x-axis\n","    ax.set_xticks(list(ax.get_xticks()) + [threshold])\n","    # Set the x-axis label\n","    plt.xlabel(\"mse\")\n","    # Set the y-axis label\n","    plt.ylabel(\"Density\")\n","    # Set the plot title\n","    plt.title(\n","        f\"PDF and KDE of Train Reconstruction Loss \\n (cut-off at mse = {round(cutoffvalue, 2)} s.th. mse > {round(cutoffvalue, 2)} is mapped to {round(cutoffvalue, 2)})\")\n","    # Add a legend\n","    plt.legend(loc='best')\n","    # Save the plot to a file\n","    # plt.savefig(output_file.replace(\".png\", \"_train_reconstruction_loss.png\"))\n","    # Show the plot\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"swvPTNDTBbcK"},"source":["### plot model history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_9Z2Rii-nvb"},"outputs":[],"source":["def plot_model_history(hist):\n","    fig = plt.figure()\n","    plt.clf()\n","    plt.plot(hist.history['loss'])\n","    plt.plot(hist.history['val_loss'])\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Training Loss', 'Validation Loss'], loc='center right')\n","    plt.title(\"Training and Validation Loss over Epochs\")\n","    return fig"]},{"cell_type":"markdown","metadata":{"id":"68bQvZMaaQbw"},"source":["### Report Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nx7YXZnWaNow"},"outputs":[],"source":["\n","def report_eval(output_file,threshold, train_recon_loss, test_recon_loss, test_ds_y, folder_path):\n","    with open(output_file, 'a', encoding=\"utf-8\") as file:\n","        label_array = np.array(test_ds_y['label'])\n","\n","        print(stats.describe(train_recon_loss))\n","        file.write(f'Train normal reconstruction loss: \\n {stats.describe(train_recon_loss)}\\n')\n","\n","        print(stats.describe(test_recon_loss[label_array == 1]))\n","        file.write(f'Test normal reconstruction loss: \\n {stats.describe(test_recon_loss[label_array == 1])}\\n')\n","\n","        print(stats.describe(test_recon_loss))\n","        file.write(f'Anomaly reconstruction loss: \\n {stats.describe(test_recon_loss)}\\n')\n","\n","        print(\n","            f'1, 99% Percentile of normal reconstruction loss is {np.percentile(train_recon_loss, 1)},'\n","            f' {np.percentile(train_recon_loss, 99)}')\n","        file.write(\n","            f'1, 99% Percentile of normal reconstruction loss is {np.percentile(train_recon_loss, 1)},'\n","            f' {np.percentile(train_recon_loss, 99)}')\n","\n","        print(\n","            f'4, 99% Percentile of abnormal reconstruction loss is {np.percentile(test_recon_loss[label_array == 1], 4)},'\n","            f' {np.percentile(test_recon_loss[label_array == 1], 99)}')\n","        file.write(\n","            f'4, 99% Percentile of abnormal reconstruction loss is {np.percentile(test_recon_loss[label_array == 1], 4)},'\n","            f' {np.percentile(test_recon_loss[label_array == 1], 99)}')\n","\n","\n","        print(f'Threshold will be {threshold}')\n","        file.write(f'\\nThreshold will be {threshold}\\n')\n","        # __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __\n","        # 1 - anomaly,\n","        # 0 - normal\n","\n","        test_recon_loss = np.array(test_recon_loss)\n","        test_y_pred = np.array([1 if x > threshold else 0 for x in test_recon_loss])\n","\n","        test_recon_loss_df = pd.DataFrame(test_recon_loss, columns=['reconstruction_loss'])\n","        test_recon_loss_df['y_pred'] = [1 if x > threshold else 0 for x in test_recon_loss]\n","        test_recon_loss_df['attack_label'] = test_ds_y['attack_label'].values\n","        test_recon_loss_df['label'] = test_ds_y['label'].values\n","        test_recon_loss_df['Threshold'] = len(test_ds_y['attack_label'].values)*[threshold]\n","\n","        test_recon_loss_df.to_csv(f'{folder_path}Reconstruction_losses.csv', index=False)\n","\n","        plot_probability_density(test_recon_loss_df, f'{folder_path}Reconstruction_loss.png',\n","                                    threshold=threshold)\n","        plot_probability_density_att(test_recon_loss_df, f'{folder_path}Reconstruction_loss.png',\n","                                            threshold=threshold)\n","\n","        #       __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __\n","        # accuracy: (tp + tn) / (p + n)\n","        accuracy = accuracy_score(test_ds_y['label'], test_y_pred)\n","\n","        print('Accuracy: %f' % accuracy, '\\n')\n","        file.write(f'Accuracy: {accuracy}\\n')\n","\n","        # precision : tp / (tp + fp)\n","        precision = precision_score(test_ds_y['label'], test_y_pred)\n","        print('Precision: %f' % precision, '\\n')\n","        file.write(f'Precision: {precision}\\n')\n","\n","        # recall: tp / (tp + fn)\n","        recall = recall_score(test_ds_y['label'], test_y_pred)\n","        print('Recall: %f' % recall, '\\n')\n","        file.write(f'Recall: {recall}\\n')\n","\n","        # F1: 2*tp / (2 tp + fp + fn)\n","        f1 = f1_score(test_ds_y['label'], test_y_pred)\n","        print('F1 score: %f' % f1, '\\n')\n","        file.write(f'F1 score: {f1}\\n')\n","\n","        # kappa\n","        kappa = cohen_kappa_score(test_ds_y['label'], test_y_pred)\n","        print('Cohens kappa: %f' % kappa, '\\n')\n","        file.write(f'Cohens kappa: {kappa}\\n')\n","\n","        # ROC AUC\n","        auc = roc_auc_score(test_ds_y['label'], test_y_pred)\n","        print('ROC AUC: %f' % auc, '\\n')\n","        file.write(f'ROC AUC: {auc}\\n')\n","\n","        # Confusion Matrix\n","        cm = confusion_matrix(test_ds_y['label'], test_y_pred)\n","        print('Confusion Matrix:', '\\n', cm, '\\n')\n","        file.write(f'Confusion Matrix:\\n {cm}\\n')\n","\n","        cm_fig = plot_confusion_matrix(cm)\n","        cm_fig.savefig(f'{folder_path}Confusion_Matrix.png')\n","\n","        cls_report = classification_report(test_ds_y['label'], test_y_pred,\n","                                           target_names=['normal', 'attacks'])\n","        print(cls_report)\n","        wrong_pred_per_class = test_ds_y[test_ds_y[\"label\"] != test_y_pred][\"attack_label\"].value_counts()\n","        correct_pred_per_class = test_ds_y[test_ds_y[\"label\"] == test_y_pred][\"attack_label\"].value_counts()\n","        preds_per_class = pd.concat([wrong_pred_per_class.rename('false'),\n","                                     correct_pred_per_class.rename('true')], axis=1).fillna(0)\n","        preds_per_class[\"false_percent\"] = round(preds_per_class[\"false\"] /\n","                                                 (preds_per_class[\"false\"] + preds_per_class[\"true\"]), 2)\n","        preds_per_class[\"support\"] = preds_per_class[\"false\"] + preds_per_class[\"true\"]\n","        preds_per_class[\"support\"] = preds_per_class[\"support\"].astype('int')\n","        preds_per_class = preds_per_class.sort_values([\"false_percent\"], axis=0, ascending=False)\n","        print(preds_per_class)\n","\n","        file.write(f'classification Report:\\n {cls_report}\\n')\n","        file.write(f'Wrong predictions per class:\\n '\n","                   f'{preds_per_class}\\n', )\n","\n","        return cls_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyCheoyIN8OS"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wTQQ4odpN84f"},"source":["## **Models**"]},{"cell_type":"markdown","metadata":{"id":"15q5vRzL96RE"},"source":["### AutoEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x5d-aW4vx69y"},"outputs":[],"source":["class Encoder:\n","    def __init__(self, hidden_layer_sizes, latent_dim, batch_norm, dropout, dropout_rate):\n","        self.input_shape = 50\n","        self.hidden_layer_sizes = hidden_layer_sizes\n","        self.latent_dim = latent_dim\n","        self.batch_norm = batch_norm\n","        self.dropout = dropout\n","        self.dropout_rate = dropout_rate\n","\n","    def build(self):\n","        inputs = Input(shape=self.input_shape, name='encoder_input')\n","        x = inputs\n","        layer_sizes =  self.hidden_layer_sizes + [self.latent_dim]\n","        for i, size in enumerate(layer_sizes[:-2]):\n","            x = Dense(layer_sizes[i+1], name=f\"Encoder-Layer{i+1}\")(x)\n","            if self.batch_norm:\n","                x = BatchNormalization(name=f'encoder-Layer-Normalization{i+1}')(x)\n","            x = LeakyReLU(name=f'Encoder-Layer-Activation{i+1}')(x)\n","            if self.dropout and K.learning_phase():\n","                x = Dropout(rate=self.dropout_rate, name=f\"Encoder-Layer{i+1}-Dropout\")(x)\n","\n","        latent_space = Dense( self.latent_dim, name=f\"Latent_space-Layer\")(x)\n","\n","        print(f\"\\nEncoder arch: D{'-D'.join(map(str, layer_sizes[1:-1]))}-D{layer_sizes[-1]}\\n\")\n","\n","        encoder = keras.Model(inputs, latent_space, name=\"encoder\")\n","        encoder.summary()\n","        return encoder\n","\n","\n","class Decoder:\n","    def __init__(self, hidden_layer_sizes, latent_dim, batch_norm, dropout, dropout_rate):\n","        self.input_shape = 50\n","        self.hidden_layer_sizes = hidden_layer_sizes\n","        self.latent_dim = latent_dim\n","        self.batch_norm = batch_norm\n","        self.dropout = dropout\n","        self.dropout_rate = dropout_rate\n","\n","    def build(self):\n","        latent_inputs = Input(shape=(self.latent_dim,), name='Decoder-input')\n","        x = latent_inputs\n","        layer_sizes = [self.latent_dim] + self.hidden_layer_sizes[::-1]\n","        for i, size in enumerate(layer_sizes[:-2]):\n","            x = Dense(layer_sizes[i+1], name=f\"Decoder-Layer{i+1}\")(x)\n","            if self.batch_norm:\n","                x = BatchNormalization(name=f'Decoder-Layer-Normalization{i+1}')(x)\n","            x = LeakyReLU(name=f'Decoder-Layer-Activation{i+1}')(x)\n","            if self.dropout and K.learning_phase():\n","                x = Dropout(rate=self.dropout_rate, name=f\"Encoder-Layer{i+1}-Dropout\")(x)\n","\n","        outputs = Dense(self.input_shape, name=f\"Output-Layer\")(x)\n","\n","        print(f\"\\nDecoder arch: D{'-D'.join(map(str, layer_sizes[0:-1]))}-D{layer_sizes[-1]}\\n\")\n","\n","        # Instantiate the decoder model:\n","        decoder = Model(latent_inputs, outputs, name='decoder')\n","        decoder.summary()\n","        return decoder\n","\n","\n","class Autoencoder(keras.Model):\n","    def __init__(self, hidden_layer_sizes, latent_dim, batch_norm=True, dropout=True, dropout_rate=0.2, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.encoder = Encoder(hidden_layer_sizes, latent_dim, batch_norm=batch_norm, dropout=dropout, dropout_rate=dropout_rate ).build()\n","        #self.encoder = Encoder(hidden_layer_sizes, latent_dim, batch_norm=batch_norm, dropout=dropout, dropout_rate=dropout_rate ).build()\n","\n","        #self.decoder = Decoder(hidden_layer_sizes, latent_dim, batch_norm=batch_norm, dropout=dropout, dropout_rate=dropout_rate).build()\n","        self.decoder = Decoder(hidden_layer_sizes, latent_dim, batch_norm=batch_norm, dropout=dropout, dropout_rate=dropout_rate).build()\n","\n","        self.lr = 0.001\n","        self.recon_loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n","        self.optimizer = tf.optimizers.RMSprop(learning_rate=self.lr)\n","        self.params = {\"lr\": self.lr,\n","                       \"epochs\": 100,\n","                       \"batch_size\": 1024}\n","\n","    def call(self, inputs):\n","        x = self.encoder(inputs)\n","        #rec1 = self.decoder1(x)\n","        #x = self.encoder2(rec1)\n","        reconstructed = self.decoder(x)\n","        return reconstructed\n"]},{"cell_type":"markdown","metadata":{"id":"oIp22UOVNGsT"},"source":["# Load DATA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16268,"status":"ok","timestamp":1683403210215,"user":{"displayName":"Νίκος Μπαζώτης","userId":"12173468501181175845"},"user_tz":-180},"id":"zCKvm2mM9j_R","outputId":"01ab75bb-2fc1-4f45-f054-607f31d815a3"},"outputs":[{"data":{"text/plain":["(601619, 42)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"dIVlbTwXDpUU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717662700235,"user_tz":-180,"elapsed":37226,"user":{"displayName":"Νίκος Μπαζώτης","userId":"12173468501181175845"}},"outputId":"97c255bd-e50a-4121-99ea-dce1454b8dd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Features Shape: (540000, 50)\n","Validation Features Shape: (180000, 50)\n","Test Features Shape: (180000, 50)\n","Train Labels Shape: (540000, 3)\n","Validation Labels Shape: (180000, 3)\n","Test Labels Shape: (180000, 3)\n"]}],"source":["ds = pd.read_csv(\"/content/drive/MyDrive/Netmode/fedxai4dga/labeled_dataset_features_scaled.csv\")\n","\n","train_ds = ds[ds['Label']==0]\n","train_ds_x = train_ds.iloc[:,:-3]\n","train_ds_y = train_ds.iloc[:,-3:]\n","\n","train_x, test_x, train_y, test_y = train_test_split(train_ds_x, train_ds_y, test_size=0.20, random_state=42)\n","train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.25, random_state=42)\n","\n","\n","# Check the shapes of the resulting DataFrames\n","print(\"Train Features Shape:\", train_x.shape)\n","print(\"Validation Features Shape:\", valid_x.shape)\n","print(\"Test Features Shape:\", test_x.shape)\n","print(\"Train Labels Shape:\", train_y.shape)\n","print(\"Validation Labels Shape:\", valid_y.shape)\n","print(\"Test Labels Shape:\", test_y.shape)"]},{"cell_type":"code","source":["train_ds[train_ds['Label']==0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"KYsmmrsmOsG3","executionInfo":{"status":"ok","timestamp":1717662589914,"user_tz":-180,"elapsed":2632,"user":{"displayName":"Νίκος Μπαζώτης","userId":"12173468501181175845"}},"outputId":"033f8059-9ada-4fb6-fe1c-d888e410b06f"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          Length  Max_DeciDig_Seq  Max_Let_Seq    Freq_A    Freq_B    Freq_C  \\\n","0       0.070437        -0.516433     0.505803 -1.026854 -0.638741  1.197386   \n","1       0.531277        -0.516433     1.035635  1.234882 -0.638741 -0.759964   \n","2       0.531277         1.794780     0.310538  1.234882 -0.638741 -0.759964   \n","3      -2.394977        -0.516433    -1.560201 -1.026854 -0.638741  1.197386   \n","4       0.662192        -0.516433     1.197035  0.571513  1.516084  1.197386   \n","...          ...              ...          ...       ...       ...       ...   \n","899995 -0.542910        -0.516433    -0.116995  0.571513  1.516084 -0.759964   \n","899996  1.685611        -0.516433     2.654803  1.614617 -0.638741 -0.759964   \n","899997 -0.112761        -0.516433     0.310538  1.614617 -0.638741 -0.759964   \n","899998 -1.097007        -0.516433    -0.610383 -1.026854 -0.638741 -0.759964   \n","899999  0.531277        -0.516433     1.035635  1.234882 -0.638741 -0.759964   \n","\n","          Freq_D    Freq_E    Freq_F    Freq_G  ...  Vowel_Freq  Vowel_Ratio  \\\n","0       1.328986  1.213176  1.719621 -0.580025  ...    0.727684     0.953612   \n","1      -0.708656  0.554760 -0.571107 -0.580025  ...    1.110954     0.773396   \n","2       1.328986  0.554760 -0.571107 -0.580025  ...    1.110954     0.773396   \n","3      -0.708656 -1.027058 -0.571107 -0.580025  ...   -2.119870    -1.981743   \n","4      -0.708656  1.841213 -0.571107 -0.580025  ...    1.467330     1.038197   \n","...          ...       ...       ...       ...  ...         ...          ...   \n","899995 -0.708656  1.213176 -0.571107 -0.580025  ...   -0.151804     0.406225   \n","899996 -0.708656  0.554760 -0.571107  1.708948  ...    3.244411     1.272379   \n","899997  1.328986 -1.027058 -0.571107 -0.580025  ...   -0.151804    -0.097364   \n","899998 -0.708656 -1.027058 -0.571107 -0.580025  ...   -2.119870    -1.981743   \n","899999  1.600808  0.554760 -0.571107  1.708948  ...    0.727684     0.285206   \n","\n","         Max_Gap  Reputation  Words_Freq  Words_Mean   Entropy  \\\n","0      -0.046436    0.607794   -0.620604    1.159694  0.546165   \n","1      -0.046436    1.351388    0.338942    0.909108 -0.156159   \n","2      -0.046436    0.665075    1.146985   -0.196548  0.742147   \n","3      -0.046436   -2.027874   -1.873262   -2.006727 -2.124258   \n","4      -0.046436    1.531662    0.338942    1.903326  0.474756   \n","...          ...         ...         ...         ...       ...   \n","899995 -0.046436   -0.028159    0.338942    0.147534 -0.410254   \n","899996 -0.046436    2.264248    1.858306    0.909108  0.749556   \n","899997 -0.046436    0.356124    1.146985   -0.196548 -0.910123   \n","899998 -0.046436   -1.396306   -0.620604   -0.370138 -1.211301   \n","899999 -0.046436    1.496994    1.146985    0.487978  0.742147   \n","\n","                                 Name  Label  Family  \n","0                     juiseforced.com      0  tranco  \n","1                  talliestionsta.com      0  tranco  \n","2               man2kotakediri.sch.id      0  tranco  \n","3                             ksc.net      0  tranco  \n","4                  renewablecities.ca      0  tranco  \n","...                               ...    ...     ...  \n","899995                   lewabets.xyz      0  tranco  \n","899996  agioskonstantinosirakleiou.gr      0  tranco  \n","899997                 vavadastsx.top      0  tranco  \n","899998                      jnswxw.cn      0  tranco  \n","899999             theguardiandns.com      0  tranco  \n","\n","[900000 rows x 53 columns]"],"text/html":["\n","  <div id=\"df-fb106a0e-f537-4188-9f76-dca766db2e66\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Length</th>\n","      <th>Max_DeciDig_Seq</th>\n","      <th>Max_Let_Seq</th>\n","      <th>Freq_A</th>\n","      <th>Freq_B</th>\n","      <th>Freq_C</th>\n","      <th>Freq_D</th>\n","      <th>Freq_E</th>\n","      <th>Freq_F</th>\n","      <th>Freq_G</th>\n","      <th>...</th>\n","      <th>Vowel_Freq</th>\n","      <th>Vowel_Ratio</th>\n","      <th>Max_Gap</th>\n","      <th>Reputation</th>\n","      <th>Words_Freq</th>\n","      <th>Words_Mean</th>\n","      <th>Entropy</th>\n","      <th>Name</th>\n","      <th>Label</th>\n","      <th>Family</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.070437</td>\n","      <td>-0.516433</td>\n","      <td>0.505803</td>\n","      <td>-1.026854</td>\n","      <td>-0.638741</td>\n","      <td>1.197386</td>\n","      <td>1.328986</td>\n","      <td>1.213176</td>\n","      <td>1.719621</td>\n","      <td>-0.580025</td>\n","      <td>...</td>\n","      <td>0.727684</td>\n","      <td>0.953612</td>\n","      <td>-0.046436</td>\n","      <td>0.607794</td>\n","      <td>-0.620604</td>\n","      <td>1.159694</td>\n","      <td>0.546165</td>\n","      <td>juiseforced.com</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.531277</td>\n","      <td>-0.516433</td>\n","      <td>1.035635</td>\n","      <td>1.234882</td>\n","      <td>-0.638741</td>\n","      <td>-0.759964</td>\n","      <td>-0.708656</td>\n","      <td>0.554760</td>\n","      <td>-0.571107</td>\n","      <td>-0.580025</td>\n","      <td>...</td>\n","      <td>1.110954</td>\n","      <td>0.773396</td>\n","      <td>-0.046436</td>\n","      <td>1.351388</td>\n","      <td>0.338942</td>\n","      <td>0.909108</td>\n","      <td>-0.156159</td>\n","      <td>talliestionsta.com</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.531277</td>\n","      <td>1.794780</td>\n","      <td>0.310538</td>\n","      <td>1.234882</td>\n","      <td>-0.638741</td>\n","      <td>-0.759964</td>\n","      <td>1.328986</td>\n","      <td>0.554760</td>\n","      <td>-0.571107</td>\n","      <td>-0.580025</td>\n","      <td>...</td>\n","      <td>1.110954</td>\n","      <td>0.773396</td>\n","      <td>-0.046436</td>\n","      <td>0.665075</td>\n","      <td>1.146985</td>\n","      <td>-0.196548</td>\n","      <td>0.742147</td>\n","      <td>man2kotakediri.sch.id</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-2.394977</td>\n","      <td>-0.516433</td>\n","      <td>-1.560201</td>\n","      <td>-1.026854</td>\n","      <td>-0.638741</td>\n","      <td>1.197386</td>\n","      <td>-0.708656</td>\n","      <td>-1.027058</td>\n","      <td>-0.571107</td>\n","      <td>-0.580025</td>\n","      <td>...</td>\n","      <td>-2.119870</td>\n","      <td>-1.981743</td>\n","      <td>-0.046436</td>\n","      <td>-2.027874</td>\n","      <td>-1.873262</td>\n","      <td>-2.006727</td>\n","      <td>-2.124258</td>\n","      <td>ksc.net</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.662192</td>\n","      <td>-0.516433</td>\n","      <td>1.197035</td>\n","      <td>0.571513</td>\n","      <td>1.516084</td>\n","      <td>1.197386</td>\n","      <td>-0.708656</td>\n","      <td>1.841213</td>\n","      <td>-0.571107</td>\n","      <td>-0.580025</td>\n","      <td>...</td>\n","      <td>1.467330</td>\n","      <td>1.038197</td>\n","      <td>-0.046436</td>\n","      <td>1.531662</td>\n","      <td>0.338942</td>\n","      <td>1.903326</td>\n","      <td>0.474756</td>\n","      <td>renewablecities.ca</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>899995</th>\n","      <td>-0.542910</td>\n","      <td>-0.516433</td>\n","      <td>-0.116995</td>\n","      <td>0.571513</td>\n","      <td>1.516084</td>\n","      <td>-0.759964</td>\n","      <td>-0.708656</td>\n","      <td>1.213176</td>\n","      <td>-0.571107</td>\n","      <td>-0.580025</td>\n","      <td>...</td>\n","      <td>-0.151804</td>\n","      <td>0.406225</td>\n","      <td>-0.046436</td>\n","      <td>-0.028159</td>\n","      <td>0.338942</td>\n","      <td>0.147534</td>\n","      <td>-0.410254</td>\n","      <td>lewabets.xyz</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","    <tr>\n","      <th>899996</th>\n","      <td>1.685611</td>\n","      <td>-0.516433</td>\n","      <td>2.654803</td>\n","      <td>1.614617</td>\n","      <td>-0.638741</td>\n","      <td>-0.759964</td>\n","      <td>-0.708656</td>\n","      <td>0.554760</td>\n","      <td>-0.571107</td>\n","      <td>1.708948</td>\n","      <td>...</td>\n","      <td>3.244411</td>\n","      <td>1.272379</td>\n","      <td>-0.046436</td>\n","      <td>2.264248</td>\n","      <td>1.858306</td>\n","      <td>0.909108</td>\n","      <td>0.749556</td>\n","      <td>agioskonstantinosirakleiou.gr</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","    <tr>\n","      <th>899997</th>\n","      <td>-0.112761</td>\n","      <td>-0.516433</td>\n","      <td>0.310538</td>\n","      <td>1.614617</td>\n","      <td>-0.638741</td>\n","      <td>-0.759964</td>\n","      <td>1.328986</td>\n","      <td>-1.027058</td>\n","      <td>-0.571107</td>\n","      <td>-0.580025</td>\n","      <td>...</td>\n","      <td>-0.151804</td>\n","      <td>-0.097364</td>\n","      <td>-0.046436</td>\n","      <td>0.356124</td>\n","      <td>1.146985</td>\n","      <td>-0.196548</td>\n","      <td>-0.910123</td>\n","      <td>vavadastsx.top</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","    <tr>\n","      <th>899998</th>\n","      <td>-1.097007</td>\n","      <td>-0.516433</td>\n","      <td>-0.610383</td>\n","      <td>-1.026854</td>\n","      <td>-0.638741</td>\n","      <td>-0.759964</td>\n","      <td>-0.708656</td>\n","      <td>-1.027058</td>\n","      <td>-0.571107</td>\n","      <td>-0.580025</td>\n","      <td>...</td>\n","      <td>-2.119870</td>\n","      <td>-1.981743</td>\n","      <td>-0.046436</td>\n","      <td>-1.396306</td>\n","      <td>-0.620604</td>\n","      <td>-0.370138</td>\n","      <td>-1.211301</td>\n","      <td>jnswxw.cn</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","    <tr>\n","      <th>899999</th>\n","      <td>0.531277</td>\n","      <td>-0.516433</td>\n","      <td>1.035635</td>\n","      <td>1.234882</td>\n","      <td>-0.638741</td>\n","      <td>-0.759964</td>\n","      <td>1.600808</td>\n","      <td>0.554760</td>\n","      <td>-0.571107</td>\n","      <td>1.708948</td>\n","      <td>...</td>\n","      <td>0.727684</td>\n","      <td>0.285206</td>\n","      <td>-0.046436</td>\n","      <td>1.496994</td>\n","      <td>1.146985</td>\n","      <td>0.487978</td>\n","      <td>0.742147</td>\n","      <td>theguardiandns.com</td>\n","      <td>0</td>\n","      <td>tranco</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>900000 rows × 53 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb106a0e-f537-4188-9f76-dca766db2e66')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fb106a0e-f537-4188-9f76-dca766db2e66 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fb106a0e-f537-4188-9f76-dca766db2e66');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cd7fd55a-4f9a-4a08-a197-630fe8a26742\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd7fd55a-4f9a-4a08-a197-630fe8a26742')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cd7fd55a-4f9a-4a08-a197-630fe8a26742 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[],"metadata":{"id":"ULxijc4yeFzr"},"execution_count":null,"outputs":[]}]}